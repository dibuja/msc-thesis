{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to pre-process the metadata downloaded from the database of interventions in congreso.es after being concatenated by legislature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = 'data/interventions/merged-by-legislature'\n",
    "title = 'all-interventions-clean.csv'\n",
    "os.chdir(f'./{workdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_29913/3680943389.py:7: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  files.append(pd.read_csv(filenames[i]))\n",
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_29913/3680943389.py:7: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  files.append(pd.read_csv(filenames[i]))\n",
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_29913/3680943389.py:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['enlace_pdf'] = data['enlace_pdf'].str.replace(r'\\#page=[\\d]{1,2}', '')\n"
     ]
    }
   ],
   "source": [
    "# Get all the file names.\n",
    "filenames = [i for i in glob.glob('*.csv')]\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(0, len(filenames)):\n",
    "    files.append(pd.read_csv(filenames[i]))\n",
    "\n",
    "# Concatenate all files in one.\n",
    "data = pd.concat(files)\n",
    "\n",
    "# Keep only useful fields.\n",
    "data = data[['legislatura', 'fecha', 'objeto_iniciativa',\n",
    "    'numero_expediente', 'autores', 'nombre_sesion',\n",
    "    'orador', 'enlace_pdf']]\n",
    "\n",
    "# Eliminate around 15 rows in L03 that are missplaced.\n",
    "l = ['NUÑEZ ENCABO, MANUEL (GS)', 'MOYA PUEYO, VICENTE',\n",
    "    'PEREZ RUBALCABA, ALFREDO', 'TOCINO BISCAROLASAGA, ISABEL (GCP)',\n",
    "    'OLLERO TASSARA, ANDRES (APDP)',\n",
    "    'MONTESINOS GARCIA, JUAN ANTONIO (GCP)',\n",
    "    'CUENCA I VALERO, MARIA EUGENIA (GMC)',\n",
    "    'GARCIA FONSECA, MANUEL (AIU-EC)', 'VILLAMOR LEON, JOSE']\n",
    "\n",
    "data = data.drop(data.loc[data['fecha'].isin(l)].index)\n",
    "\n",
    "# Eliminate 4 rows of data with errors.\n",
    "l2 = ['COMPARECENCIA DE AUTORIDADES Y FUNCIONARIOS EN COMISION.', \n",
    "      'COMPARECENCIA DEL GOBIERNO EN COMISION (ART. 44).']\n",
    "\n",
    "data = data.drop(data.loc[data['legislatura'].isin(l2)].index)\n",
    "\n",
    "# Eliminating 2 rows in L06 that are missplaced.\n",
    "data = data.loc[(data['fecha'] != 'Pregunta-Contestación')]\n",
    "\n",
    "# Fecha to datetime format.\n",
    "data['fecha'] = pd.to_datetime(data['fecha'], format='%d/%m/%Y')\n",
    "\n",
    "# Removing the  page reference since it is not needed and does not allow to drop duplicates.\n",
    "data = data.astype({'enlace_pdf':'string'})\n",
    "data['enlace_pdf'] = data['enlace_pdf'].str.replace(r'\\#page=[\\d]{1,2}', '')\n",
    "\n",
    "# Remove duplicates.\n",
    "data = data.sort_values(by=['fecha']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Eliminate NaNs.\n",
    "data = data.dropna()\n",
    "\n",
    "# Eliminate rows if they correspond to constitution of commissions because these are irrelevant.\n",
    "data = data[data['objeto_iniciativa'].str.contains('Constitución de la Comisión') == False]\n",
    "\n",
    "# Reset index.\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Substitute roman numbers for integers values.\n",
    "data['legislatura'] = data['legislatura'].replace({'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10, 'XI': 11, 'XII': 12, 'XIII': 13, 'XIV': 14})\n",
    "\n",
    "# Save new file.\n",
    "data.to_csv(f'../{title}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we can only obtain the texts for legislatures 6 until 14, I splitted this data into another .csv file.\n",
    "vi_to_xiv = data.loc[data['legislatura'] > 5].reset_index(drop=True)\n",
    "vi_to_xiv.to_csv(f'../vi-xiv-clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
