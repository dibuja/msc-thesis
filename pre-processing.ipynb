{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to pre-process the metadata downloaded from the database of interventions in congreso.es after being concatenated by legislature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = 'data/interventions/merged-by-legislature'\n",
    "title = 'all-interventions-clean.csv'\n",
    "os.chdir(f'./{workdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the file names.\n",
    "filenames = [i for i in glob.glob('*.csv')]\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(0, len(filenames)):\n",
    "    files.append(pd.read_csv(filenames[i]))\n",
    "\n",
    "# Concatenate all files in one.\n",
    "data = pd.concat(files)\n",
    "\n",
    "# Keep only useful fields.\n",
    "data = data[['legislatura', 'fecha', 'objeto_iniciativa',\n",
    "    'numero_expediente', 'autores', 'nombre_sesion',\n",
    "    'orador', 'enlace_pdf']]\n",
    "\n",
    "# Eliminate around 15 rows in L03 that are missplaced.\n",
    "l = ['NUÑEZ ENCABO, MANUEL (GS)', 'MOYA PUEYO, VICENTE',\n",
    "    'PEREZ RUBALCABA, ALFREDO', 'TOCINO BISCAROLASAGA, ISABEL (GCP)',\n",
    "    'OLLERO TASSARA, ANDRES (APDP)',\n",
    "    'MONTESINOS GARCIA, JUAN ANTONIO (GCP)',\n",
    "    'CUENCA I VALERO, MARIA EUGENIA (GMC)',\n",
    "    'GARCIA FONSECA, MANUEL (AIU-EC)', 'VILLAMOR LEON, JOSE']\n",
    "\n",
    "data = data.drop(data.loc[data['fecha'].isin(l)].index)\n",
    "\n",
    "# Eliminating 2 rows in L06 that are missplaced.\n",
    "data = data.loc[(data['fecha'] != 'Pregunta-Contestación')]\n",
    "\n",
    "# Fecha to datetime format.\n",
    "data['fecha'] = pd.to_datetime(data['fecha'], format='%d/%m/%Y')\n",
    "\n",
    "# Removing the  page reference since it is not needed and does not allow to drop duplicates.\n",
    "data = data.astype({'enlace_pdf':'string'})\n",
    "data['enlace_pdf'] = data['enlace_pdf'].str.replace(r'\\#page=[\\d]{1,2}', '')\n",
    "\n",
    "# Remove duplicates.\n",
    "data = data.sort_values(by=['fecha']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Eliminate NaNs.\n",
    "data = data.dropna()\n",
    "\n",
    "# Eliminate rows if they correspond to constitution of commissions because these are irrelevant.\n",
    "data = data[data['objeto_iniciativa'].str.contains('Constitución de la Comisión') == False]\n",
    "\n",
    "# Reset index.\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Save new file.\n",
    "data.to_csv(f'../{title}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we can only obtain the texts for legislatures 6 until 14, I splitted this data into another .csv file.\n",
    "leg = ['VI', 'VII', 'VIII', 'IX', 'X', 'XI', 'XII', 'XIII', 'XIV']\n",
    "vi_to_xiv = data.loc[data['legislatura'].isin(leg)].reset_index(drop=True)\n",
    "vi_to_xiv.to_csv(f'../vi-xiv-clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
